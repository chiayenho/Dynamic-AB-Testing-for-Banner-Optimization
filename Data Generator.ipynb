{"cells":[{"cell_type":"markdown","source":["# Simulation Data Generator\nTo build a demo and illustrate how our Dynamic A/B Testing works, we used [a kaggle dataset](https://www.kaggle.com/datasets/podsyp/how-to-do-product-analytics) to generate some simulated data for each timestep under each strategy (stored in two folders). Our demo will then go through the timestep and choose from the two folders to simulate the decision making process."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"1f332600-0b17-4f00-bed7-7d3ef053d05a"}}},{"cell_type":"code","source":["from pyspark.sql import functions as F\n# URL processing\nimport urllib\nimport datetime\n\n# Setup. Eg. strategy 1 is 80% Banner 0, 20% Banner 1\nstrategy_0 = [0.8, 0.2]\nstrategy_1 = [0.2, 0.8]"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"1a4aea2d-79da-46f2-ad0f-43cd54e1ca4d"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["# Read raw data and do some transformation\nmy_upload_path = \"dbfs:/FileStore/shared_uploads/WAN00316@umn.edu/sample_product.csv\"\nraw = spark.read.csv(my_upload_path, header=True, inferSchema=True)\nraw.show(5)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"362bc140-f7c4-4da9-b047-703ca776dd55"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"+------+--------+-------------------+------+\n|banner| product|               time|target|\n+------+--------+-------------------+------+\n|     0| clothes|2019-02-01 00:00:39|   0.0|\n|     1|sneakers|2019-02-01 00:00:45|   0.0|\n|     1|sneakers|2019-02-01 00:01:06|   0.0|\n|     0| clothes|2019-02-01 00:01:56|   0.0|\n|     0| clothes|2019-02-01 00:02:22|   0.0|\n+------+--------+-------------------+------+\nonly showing top 5 rows\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["+------+--------+-------------------+------+\n|banner| product|               time|target|\n+------+--------+-------------------+------+\n|     0| clothes|2019-02-01 00:00:39|   0.0|\n|     1|sneakers|2019-02-01 00:00:45|   0.0|\n|     1|sneakers|2019-02-01 00:01:06|   0.0|\n|     0| clothes|2019-02-01 00:01:56|   0.0|\n|     0| clothes|2019-02-01 00:02:22|   0.0|\n+------+--------+-------------------+------+\nonly showing top 5 rows\n\n"]}}],"execution_count":0},{"cell_type":"code","source":["data_path = \"dbfs:/FileStore/simulated_data\"\ntimesteps = 120\nstart_time = datetime.datetime(2019,2,1)\ntime_step_interval = datetime.timedelta(hours=12)\n\nfor timestep in range(timesteps):\n    period = raw[(raw['time']>=start_time) & (raw['time']<=start_time + time_step_interval)] # filter out time period\n    period_upsampled = period.withColumn(\"dummy\", explode(array([lit(x) for x in range(10)]))).drop('dummy') # upsample by 10X since data is a bit sparse\n    for strategy_num in [0,1]:\n        sampled = period_upsampled.sampleBy('product', dict(zip(banners, eval('strategy_{}'.format(strategy_num))))) # sample by strategy setup\n        # Save the file to the right folder\n        sampled.coalesce(1).write.mode(\"overwrite\").option(\"header\", \"true\").csv(data_path + '/tmp')\n        csv_file = [file.path for file in dbutils.fs.ls(data_path + '/tmp') if file.path.endswith('.csv')][0]\n        dbutils.fs.mv(csv_file, 'dbfs:/FileStore/simulated_data/strategy_{}/timestep_{}.csv'.format(strategy_num, timestep))\n    start_time += time_step_interval"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"1873659d-7977-4f13-8d45-f049cb455e23"}},"outputs":[],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"TrendsMkt Data Generator","dashboards":[],"notebookMetadata":{"pythonIndentUnit":4},"language":"python","widgets":{},"notebookOrigID":3383076411913942}},"nbformat":4,"nbformat_minor":0}
